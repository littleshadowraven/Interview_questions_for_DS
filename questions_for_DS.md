# Вопрос-ответ для Data Scientist.

## 1. В чём разница между контролируемым и неконтролируемым машинным обучением?

**Контролируемое машинное обучение:**
- Использует известные и маркированные данные в качестве входных.
- Имеет механизм обратной связи.
- Наиболее часто используемые алгоритмы контролируемого обучения — деревья решений, логистическая регрессия и метод опорных векторов. 

**Неконтролируемое обучение:**
- Использует немаркированные данные в качестве входных.
- Не имеет механизма обратной связи. 
- Наиболее часто используемые алгоритмы неконтролируемого обучения — кластеризация методом k-средних, иерархическая кластеризация и априорный алгоритм.

<div align="right">
    <b><a href="#">↥ вернуться к началу</a></b><br>
</div>

## 2. Перечислите этапы построения дерева решений

1. Взять весь набор входных данных.
2. Вычислить энтропию целевой переменной, а также прогнозные атрибуты.
3. Рассчитать прирост информации по всем атрибутам (информацию о том, как отсортировать разные объекты друг от друга).
4. Выбрать атрибут с наибольшим объёмом информации в качестве корневого узла.
5. Повторить ту же процедуру для каждой ветви, пока узел решения каждой ветви не будет завершён.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/265/92f/e0a/26592fe0aea12078895f008254132774.jpg)

<div align="right">
    <b><a href="#">↥ вернуться к началу</a></b><br>
</div>

## 3. Что такое проблемы взрывающегося и затухающего градиента?

**Градиент** — это вектор частных производных функции потерь по весам нейросети. Он показывает вектор наибольшего роста функции для всех весов.

В процессе обучения при обратном распространении ошибки при прохождении через слои нейронной сети в элементах градиента могут накапливаться большие значения, что будет приводить к сильным изменениям весов. Это дестабилизирует алгоритм нейросети. Эта проблема называется взрывающимся градиентом.

Аналогичная обратная проблема, в которой при прохождении ошибки через слои градиент становится меньше, называется затухающим градиентом. 

Чем больше количество слоев нейросети, тем выше риски данных ошибок. Для решения сложных задач с помощью нейронных сетей необходимо уметь определять и устранять её.
![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/985/6f6/112/9856f6112076a8762cad864324aaea7b.png)

<div align="right">
    <b><a href="#">↥ вернуться к началу</a></b><br>
</div>

## 4. Как рассчитать точность прогноза, используя матрицу ошибок?

В матрице ошибок есть значения для общего количества данных, истинных значений и прогнозируемых значений.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/5ea/1fc/1eb/5ea1fc1ebc989a3cfae2d1d9e0e9a5e9.png)

**Формула точности:**
Точность = (истинно положительные + истинно отрицательные) / общее количество наблюдений. 

Предположим, что истинно положительных значений у нас 2981, истинно отрицательных — 110, а всего — 3311. Используя формулу, находим, что точность прогноза составляет 93,36 %.

<div align="right">
    <b><a href="#">↥ вернуться к началу</a></b><br>
</div>

## 5. Как работает ROC-кривая?

**ROC-кривая** — это графическое изображение контраста между показателями истинно положительных и ложноположительных результатов при различных пороговых значениях. 

Если считать TPR и FPR для фиксированного порога μ є [0,1], то их можно представить в виде функций от аргумента μ:

TPR = TPR(μ), FPR = FPR(μ). При этом обе функции монотонно возрастают от 0 до 1, а значит, определена функция:

ROC(x) = TPR(FPR-1(x)), x є [0,1]

ROC-кривая — это график функции.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/11a/7ed/892/11a7ed892fa1d3bce70dab7e09cc1405.png)

Как правило, у хорошего классификатора кривая лежит по большей части либо целиком выше прямой y=x. Это связано с тем что при хорошей классификации надо получать максимальный TPR при минимальном FPR.

<div align="right">
    <b><a href="#">↥ вернуться к началу</a></b><br>
</div>

## 6. Объясните алгоритм машинного обучения SVM

**SVM, или метод опорных векторов,** — это набор алгоритмов обучения с учителем, который используется для классификации и регрессионного анализа. 

Его основная идея — построение гиперплоскости, которая разделяет объекты выборки максимально эффективным способом. Сделать это можно с помощью алгоритма линейной классификации.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/1d9/b22/f52/1d9b22f525ee5a2030004de4e70b07f1.png)

<div align="right">
    <b><a href="#">↥ вернуться к началу</a></b><br>
</div>

## 7. Что такое ансамбль методов?

**Ансамбль методов** — это использование нескольких алгоритмов с целью получения более высокой эффективности прогнозирования, чем можно было бы получить, используя эти алгоритмы отдельно.

<div align="right">
    <b><a href="#">↥ вернуться к началу</a></b><br>
</div>

## 8. Что такое Random Forest?

**Random Forest, или случайный лес,** — это один из немногих универсальных алгоритмов обучения, который способен выполнять задачи классификации, регрессии и кластеризации. 

Случайный лес состоит из большого количества отдельных деревьев решений, которые по сути являются ансамблем методов. Каждое дерево в случайном лесу возвращает прогноз класса, и класс с наибольшим количеством голосов становится прогнозом леса.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/760/22c/639/76022c639a99e2535c7cfffb5b358ca1.jpg)

<div align="right">
    <b><a href="#">↥ вернуться к началу</a></b><br>
</div>

## 9. Какой метод перекрёстной проверки вы бы использовали для набора данных временных рядов?

Нормальная k-кратная процедура перекрёстной проверки может быть проблематичной для временных рядов. 

Наиболее результативный подход для временных рядов — это прямая цепочка, где процедура выглядит примерно так:

сгиб 1: тренировка [1], тест [2];
сгиб 2: тренировка [1 2], тест [3];
сгиб 3: тренировка [1 2 3], тест [4];
сгиб 4: тренировка [1 2 3 4], тест [5];
сгиб 5: тренировка [1 2 3 4 5], тест [6].

Это более точно показывает ситуацию, где можно моделировать прошлые данные и прогнозировать прогнозные данные.

<div align="right">
    <b><a href="#">↥ вернуться к началу</a></b><br>
</div>

## 10. Что такое логистическая регрессия? Или приведите пример логистической регрессии.

**Логистическая регрессия** — это статистическая модель, которую используют для прогнозирования вероятности какого-либо события.

Например, нужно предсказать, победит конкретный политический лидер на выборах или нет. 

В этом случае результат прогноза будет двоичным, то есть 0 или 1 (выигрыш/проигрыш). В качестве переменных-предикторов здесь будут: сумма денег, потраченных на предвыборную агитацию конкретного кандидата, количество времени, затраченного на агитацию, и так далее.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/64d/16e/c56/64d16ec56cb9f1c43c7df767e8e75f81.png)

<div align="right">
    <b><a href="#">↥ вернуться к началу</a></b><br>
</div>

## 11. Что вы понимаете под термином «нормальное распределение»?

**Нормальное распределение** — одно из основных распределений вероятности. 
Плотность нормального распределения выражается функцией Гаусса:

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/2b0/fa8/b39/2b0fa8b39ec556d14f908c804e2df981.png)

Где μ — математическое ожидание, σ — среднеквадратическое отклонение, σ ² — дисперсия, медиана и мода нормального распределения равны математическому ожиданию μ.

Примеры нормального распределения: погрешности измерений, отклонения при стрельбе, показатели живых популяций в природе.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/773/413/33a/77341333a38caef38b28e4927ce30526.jpg)

<div align="right">
    <b><a href="#">↥ вернуться к началу</a></b><br>
</div>

## 12. Что такое глубокое обучение?

**Глубокое обучение** — совокупность большого количества методов машинного обучения, основанных на имитации работы человеческого мозга в процессе обработки данных и принятия решений.

По сути они основаны на обучении представлениям, а не специализированным алгоритмам под конкретные задачи. Из-за чего обучение нейронных сетей ведётся дольше, чем традиционное машинное обучение, но точность результатов получается выше.

<div align="right">
    <b><a href="#">↥ вернуться к началу</a></b><br>
</div>

## 13. В чём разница между машинным обучением и глубоким обучением?

Машинное обучение позволяет обучать компьютерную систему без её фактического программирования. А глубокое обучение — это подвид машинного обучения, который основан на аналогии нейронных сетей человеческого мозга. Это похоже на то, как наш мозг работает для решения проблем: чтобы найти ответ, он пропускает запросы через различные иерархии концепций и связанных вопросов.

<div align="right">
    <b><a href="#">↥ вернуться к началу</a></b><br>
</div>

## 14. Что такое рекуррентные нейронные сети (RNN)?

**Рекуррентные нейронные сети** — это вид нейросетей, в которых связи между элементами образуют направленную последовательность. Это позволяет обрабатывать серии событий во времени или последовательные пространственные цепочки. 

Они используются преимущественно для задач, где нечто цельное состоит из ряда объектов, например при распознавании рукописного текста или речи.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/018/ded/34a/018ded34ad2c5491ca1295a569770b00.png)

<div align="right">
    <b><a href="#">↥ вернуться к началу</a></b><br>
</div>

## 15. Что такое обучение с подкреплением?

**Обучение с подкреплением** очень схоже по смыслу с обучением с учителем, но в роли учителя выступает среда, в которой система может выполнять какие-либо действия.

Обучение с подкреплением активно используется в задачах, где нужно выбрать лучший вариант среди многих или достичь сложной цели за множество ходов. К примеру, это могут быть шахматы или го, где нейросети дают только правила, а она совершенствует свои навыки с помощью игр с самой собой.

Машина пытается решить задачу, ошибается, учится на своих ошибках, совершенствуется, и так множество раз.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/339/03b/e83/33903be8305635e545925dd6c7f69e74.png)

<div align="right">
    <b><a href="#">↥ вернуться к началу</a></b><br>
</div>

## 16. Объясните, что такое регуляризация и почему она полезна

**Регуляризация в машинном обучении** — метод добавления дополнительных ограничений к условию для того, чтобы предотвратить переобучение системы или решить некорректно поставленную задачу. Часто это ограничение представляет собой штраф за излишнюю сложность модели.

Прогнозы модели должны затем минимизировать функцию потерь, вычисленную на регуляризованном обучающем наборе.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/c49/c4b/6e7/c49c4b6e75445bbfd43263347df6533b.png)

<div align="right">
    <b><a href="#">↥ вернуться к началу</a></b><br>
</div>

## 17. Что такое рекомендательные системы?

Подкласс систем фильтрации информации, что применяются для прогнозирования предпочтений или оценок, которые пользователь поставит продукту. Рекомендательные системы широко используются в фильмах, новостях, статьях, товарах, музыке и так далее.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/d27/405/bb2/d27405bb2c63415858c179fe22929ead.png)

<div align="right">
    <b><a href="#">↥ вернуться к началу</a></b><br>
</div>

## 18. Какова цель A/B-тестирования? 

**A/B-тестирование** — это статистическая проверка гипотез для рандомизированных экспериментов с двумя переменными, A и B. 

Его цель — обнаружение любых изменений на веб-странице, чтобы максимизировать или повысить результат стратегии.

<div align="right">
    <b><a href="#">↥ вернуться к началу</a></b><br>
</div>

## 19. Что такое закон больших чисел?

Это принцип теории вероятностей, который описывает результат выполнения одного и того же эксперимента множество раз. 

При достаточно длительной серии экспериментов закон больших чисел гарантирует устойчивость средних значений от случайных событий. И среднее значение конечной выборки фиксированного распределения будет очень близко к математическому ожиданию выборки.

К примеру, при бросках шестигранного кубика. Чем больше бросков, тем больше среднее значение близится к математическому ожиданию 3,5.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/6d5/4ba/83b/6d54ba83b3ec6bbb47716244b233e59f.png)

<div align="right">
    <b><a href="#">↥ вернуться к началу</a></b><br>
</div>

## 20. Назовите несколько фреймворков для глубокого обучения

- Pytorch.
- TensorFlow.
- Microsoft Cognitive Toolkit.
- Keras.
- Caffe.
- Chainer.

<div align="right">
    <b><a href="#">↥ вернуться к началу</a></b><br>
</div>

## 21. Какие задачи ML бывают?

1. **Обучение с учителем**

- **бинарная классификация:** объект может принимать только одно значение из 2х (Пример: определения письма на почте - спам / не спам)

- **многоклассовая классификация:** объект может принимать только одно значение из конечного n > 2 (Пример: определение категории письма на почте - чеки/госписьма/рассылки/маркетплейсы/спорт/новости/рабочие)

- **мультилейбл классификация:** объект может принимать несколько значений из конечного n > 2 (Пример, определение топика новостей: новость может быть и про спорт и про политику одновременно)

- **регрессия:** тут предсказываем уже не класс, а вещественное число (Пример: прогнозирование цены на квартиру)

- **ранжирование:** применяется, когда нужно уметь упорядочивать объекты попарно, списком или проставлять число релеватности, например, от 0 до 1 (Пример: рекомендательные системы, поисковые сервисы)

![Виды классификаци](https://habrastorage.org/r/w780/getpro/habr/upload_files/ed7/607/381/ed7607381fdc9ca92170d79aa7bbfbda.png)

![Пример задачи регрессии](https://habrastorage.org/r/w780/getpro/habr/upload_files/99d/012/b07/99d012b07abb2111dc0505d9081b762d.png)

2. **Обучение без учителя:** По данным модель будет делать вывод о том, как сгруппировать объекты, мы заранее не имеем никакой разметки

- **кластеризация** (пример: сгруппировать отзывы на продукт по тематике, заранее мы не знаем, на какие топики можно поделить отзывы - кластеризация нам в этом поможет)

![](https://habrastorage.org/r/w780/getpro/habr/upload_files/b75/fe6/935/b75fe69350c6210cd5ecf239461c2c53.png)

3. **Обучение с подкреплением:** отдельная большая сложная область машинного обучения, но обычно она выходит за рамки стандартных роадмапов изучения профессии

![](https://habrastorage.org/r/w780/getpro/habr/upload_files/026/eee/814/026eee814d30005197392d62e283475d.png)

<div align="right">
    <b><a href="#">↥ вернуться к началу</a></b><br>
</div>

## 22. Какие признаки бывают?

- Числовые (возраст, цена)
- Категориальные (цвет, страна)
- Ordinal (Упорядоченные категориальные)
- Булевы (да/нет)
- Временные ряды (температура по дням)
- Текстовые (описание товара)
- Изображения (пиксели)

<div align="right">
    <b><a href="#">↥ вернуться к началу</a></b><br>
</div>

## 23. Почему переобучение это плохо? Как с ним можно бороться?

**Переобучение** — это ситуация, когда модель слишком хорошо подстраивается под обучающую выборку, включая её шум и выбросы, и теряет способность обобщать на новые, невиданные данные. В итоге, она показывает отличные результаты на тренировке, но проваливается на валидации или в продакшене. Это значит, что модель запомнила данные, а не угадывает закономерность.

![](https://habrastorage.org/r/w780/getpro/habr/upload_files/317/d1c/a72/317d1ca727e47effc2ec1af226f302ab.png)

**Основная цель ML-модели** — хорошо работать на новых данных, а не просто запомнить старые, поэтому с переобучением обязательно нужно бороться и предотвращать его.

**Как бороться с переобучением:**
- **Регуляризация** — добавление штрафа к функции потерь (например, L1 или L2), чтобы ограничить сложность модели.
- **Аугментация данных** — особенно в компьютерном зрении или NLP, помогает расширить датасет и сделать модель устойчивее.
- **Упрощение модели** — уменьшение количества параметров, глубины нейросети / решающего дерева и т.п.
- **Собирание большего количества данных** — лучший способ повысить обобщающую способность, если есть возможность.

<div align="right">
    <b><a href="#">↥ вернуться к началу</a></b><br>
</div>