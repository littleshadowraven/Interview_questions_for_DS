# Вопрос-ответ для Data Scientist.

## 1. В чём разница между контролируемым и неконтролируемым машинным обучением?

**Контролируемое машинное обучение:**
- Использует известные и маркированные данные в качестве входных.
- Имеет механизм обратной связи.
- Наиболее часто используемые алгоритмы контролируемого обучения — деревья решений, логистическая регрессия и метод опорных векторов. 

**Неконтролируемое обучение:**
- Использует немаркированные данные в качестве входных.
- Не имеет механизма обратной связи. 
- Наиболее часто используемые алгоритмы неконтролируемого обучения — кластеризация методом k-средних, иерархическая кластеризация и априорный алгоритм.


## 2. Перечислите этапы построения дерева решений

1. Взять весь набор входных данных.
2. Вычислить энтропию целевой переменной, а также прогнозные атрибуты.
3. Рассчитать прирост информации по всем атрибутам (информацию о том, как отсортировать разные объекты друг от друга).
4. Выбрать атрибут с наибольшим объёмом информации в качестве корневого узла.
5. Повторить ту же процедуру для каждой ветви, пока узел решения каждой ветви не будет завершён.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/265/92f/e0a/26592fe0aea12078895f008254132774.jpg)


## 3. Что такое проблемы взрывающегося и затухающего градиента?

**Градиент** — это вектор частных производных функции потерь по весам нейросети. Он показывает вектор наибольшего роста функции для всех весов.

В процессе обучения при обратном распространении ошибки при прохождении через слои нейронной сети в элементах градиента могут накапливаться большие значения, что будет приводить к сильным изменениям весов. Это дестабилизирует алгоритм нейросети. Эта проблема называется взрывающимся градиентом.

Аналогичная обратная проблема, в которой при прохождении ошибки через слои градиент становится меньше, называется затухающим градиентом. 

Чем больше количество слоев нейросети, тем выше риски данных ошибок. Для решения сложных задач с помощью нейронных сетей необходимо уметь определять и устранять её.
![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/985/6f6/112/9856f6112076a8762cad864324aaea7b.png)


## 4. Как рассчитать точность прогноза, используя матрицу ошибок?

В матрице ошибок есть значения для общего количества данных, истинных значений и прогнозируемых значений.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/5ea/1fc/1eb/5ea1fc1ebc989a3cfae2d1d9e0e9a5e9.png)

**Формула точности:**
Точность = (истинно положительные + истинно отрицательные) / общее количество наблюдений. 

Предположим, что истинно положительных значений у нас 2981, истинно отрицательных — 110, а всего — 3311. Используя формулу, находим, что точность прогноза составляет 93,36 %.


## 5. Как работает ROC-кривая?

**ROC-кривая** — это графическое изображение контраста между показателями истинно положительных и ложноположительных результатов при различных пороговых значениях. 

Если считать TPR и FPR для фиксированного порога μ є [0,1], то их можно представить в виде функций от аргумента μ:

TPR = TPR(μ), FPR = FPR(μ). При этом обе функции монотонно возрастают от 0 до 1, а значит, определена функция:

ROC(x) = TPR(FPR-1(x)), x є [0,1]

ROC-кривая — это график функции.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/11a/7ed/892/11a7ed892fa1d3bce70dab7e09cc1405.png)

Как правило, у хорошего классификатора кривая лежит по большей части либо целиком выше прямой y=x. Это связано с тем что при хорошей классификации надо получать максимальный TPR при минимальном FPR.


## 6. Объясните алгоритм машинного обучения SVM

**SVM, или метод опорных векторов,** — это набор алгоритмов обучения с учителем, который используется для классификации и регрессионного анализа. 

Его основная идея — построение гиперплоскости, которая разделяет объекты выборки максимально эффективным способом. Сделать это можно с помощью алгоритма линейной классификации.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/1d9/b22/f52/1d9b22f525ee5a2030004de4e70b07f1.png)


## 7. Что такое ансамбль методов?

**Ансамбль методов** — это использование нескольких алгоритмов с целью получения более высокой эффективности прогнозирования, чем можно было бы получить, используя эти алгоритмы отдельно.


## 8. Что такое Random Forest?

**Random Forest, или случайный лес,** — это один из немногих универсальных алгоритмов обучения, который способен выполнять задачи классификации, регрессии и кластеризации. 

Случайный лес состоит из большого количества отдельных деревьев решений, которые по сути являются ансамблем методов. Каждое дерево в случайном лесу возвращает прогноз класса, и класс с наибольшим количеством голосов становится прогнозом леса.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/760/22c/639/76022c639a99e2535c7cfffb5b358ca1.jpg)


## 9. Какой метод перекрёстной проверки вы бы использовали для набора данных временных рядов?

Нормальная k-кратная процедура перекрёстной проверки может быть проблематичной для временных рядов. 

Наиболее результативный подход для временных рядов — это прямая цепочка, где процедура выглядит примерно так:

сгиб 1: тренировка [1], тест [2];
сгиб 2: тренировка [1 2], тест [3];
сгиб 3: тренировка [1 2 3], тест [4];
сгиб 4: тренировка [1 2 3 4], тест [5];
сгиб 5: тренировка [1 2 3 4 5], тест [6].

Это более точно показывает ситуацию, где можно моделировать прошлые данные и прогнозировать прогнозные данные.


## 10. Что такое логистическая регрессия? Или приведите пример логистической регрессии.

**Логистическая регрессия** — это статистическая модель, которую используют для прогнозирования вероятности какого-либо события.

Например, нужно предсказать, победит конкретный политический лидер на выборах или нет. 

В этом случае результат прогноза будет двоичным, то есть 0 или 1 (выигрыш/проигрыш). В качестве переменных-предикторов здесь будут: сумма денег, потраченных на предвыборную агитацию конкретного кандидата, количество времени, затраченного на агитацию, и так далее.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/64d/16e/c56/64d16ec56cb9f1c43c7df767e8e75f81.png)


## 11. Что вы понимаете под термином «нормальное распределение»?

**Нормальное распределение** — одно из основных распределений вероятности. 
Плотность нормального распределения выражается функцией Гаусса:

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/2b0/fa8/b39/2b0fa8b39ec556d14f908c804e2df981.png)

Где μ — математическое ожидание, σ — среднеквадратическое отклонение, σ ² — дисперсия, медиана и мода нормального распределения равны математическому ожиданию μ.

Примеры нормального распределения: погрешности измерений, отклонения при стрельбе, показатели живых популяций в природе.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/773/413/33a/77341333a38caef38b28e4927ce30526.jpg)


## 12. Что такое глубокое обучение?

**Глубокое обучение** — совокупность большого количества методов машинного обучения, основанных на имитации работы человеческого мозга в процессе обработки данных и принятия решений.

По сути они основаны на обучении представлениям, а не специализированным алгоритмам под конкретные задачи. Из-за чего обучение нейронных сетей ведётся дольше, чем традиционное машинное обучение, но точность результатов получается выше.


## 13. В чём разница между машинным обучением и глубоким обучением?

Машинное обучение позволяет обучать компьютерную систему без её фактического программирования. А глубокое обучение — это подвид машинного обучения, который основан на аналогии нейронных сетей человеческого мозга. Это похоже на то, как наш мозг работает для решения проблем: чтобы найти ответ, он пропускает запросы через различные иерархии концепций и связанных вопросов.


## 14. Что такое рекуррентные нейронные сети (RNN)?

**Рекуррентные нейронные сети** — это вид нейросетей, в которых связи между элементами образуют направленную последовательность. Это позволяет обрабатывать серии событий во времени или последовательные пространственные цепочки. 

Они используются преимущественно для задач, где нечто цельное состоит из ряда объектов, например при распознавании рукописного текста или речи.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/018/ded/34a/018ded34ad2c5491ca1295a569770b00.png)


## 15. Что такое обучение с подкреплением?

**Обучение с подкреплением** очень схоже по смыслу с обучением с учителем, но в роли учителя выступает среда, в которой система может выполнять какие-либо действия.

Обучение с подкреплением активно используется в задачах, где нужно выбрать лучший вариант среди многих или достичь сложной цели за множество ходов. К примеру, это могут быть шахматы или го, где нейросети дают только правила, а она совершенствует свои навыки с помощью игр с самой собой.

Машина пытается решить задачу, ошибается, учится на своих ошибках, совершенствуется, и так множество раз.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/339/03b/e83/33903be8305635e545925dd6c7f69e74.png)


## 16. Объясните, что такое регуляризация и почему она полезна

**Регуляризация в машинном обучении** — метод добавления дополнительных ограничений к условию для того, чтобы предотвратить переобучение системы или решить некорректно поставленную задачу. Часто это ограничение представляет собой штраф за излишнюю сложность модели.

Прогнозы модели должны затем минимизировать функцию потерь, вычисленную на регуляризованном обучающем наборе.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/c49/c4b/6e7/c49c4b6e75445bbfd43263347df6533b.png)


## 17. Что такое рекомендательные системы?

Подкласс систем фильтрации информации, что применяются для прогнозирования предпочтений или оценок, которые пользователь поставит продукту. Рекомендательные системы широко используются в фильмах, новостях, статьях, товарах, музыке и так далее.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/d27/405/bb2/d27405bb2c63415858c179fe22929ead.png)


## 18. Какова цель A/B-тестирования? 

**A/B-тестирование** — это статистическая проверка гипотез для рандомизированных экспериментов с двумя переменными, A и B. 

Его цель — обнаружение любых изменений на веб-странице, чтобы максимизировать или повысить результат стратегии.

## 19. Что такое закон больших чисел?

Это принцип теории вероятностей, который описывает результат выполнения одного и того же эксперимента множество раз. 

При достаточно длительной серии экспериментов закон больших чисел гарантирует устойчивость средних значений от случайных событий. И среднее значение конечной выборки фиксированного распределения будет очень близко к математическому ожиданию выборки.

К примеру, при бросках шестигранного кубика. Чем больше бросков, тем больше среднее значение близится к математическому ожиданию 3,5.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/6d5/4ba/83b/6d54ba83b3ec6bbb47716244b233e59f.png)


## 20. Назовите несколько фреймворков для глубокого обучения

- Pytorch.
- TensorFlow.
- Microsoft Cognitive Toolkit.
- Keras.
- Caffe.
- Chainer.

## 21. Какие задачи ML бывают?

1. **Обучение с учителем**

- **бинарная классификация:** объект может принимать только одно значение из 2х (Пример: определения письма на почте - спам / не спам)

- **многоклассовая классификация:** объект может принимать только одно значение из конечного n > 2 (Пример: определение категории письма на почте - чеки/госписьма/рассылки/маркетплейсы/спорт/новости/рабочие)

- **мультилейбл классификация:** объект может принимать несколько значений из конечного n > 2 (Пример, определение топика новостей: новость может быть и про спорт и про политику одновременно)

- **регрессия:** тут предсказываем уже не класс, а вещественное число (Пример: прогнозирование цены на квартиру)

- **ранжирование:** применяется, когда нужно уметь упорядочивать объекты попарно, списком или проставлять число релеватности, например, от 0 до 1 (Пример: рекомендательные системы, поисковые сервисы)

![Виды классификаци](https://habrastorage.org/r/w780/getpro/habr/upload_files/ed7/607/381/ed7607381fdc9ca92170d79aa7bbfbda.png)

![Пример задачи регрессии](https://habrastorage.org/r/w780/getpro/habr/upload_files/99d/012/b07/99d012b07abb2111dc0505d9081b762d.png)

2. **Обучение без учителя:** По данным модель будет делать вывод о том, как сгруппировать объекты, мы заранее не имеем никакой разметки

- **кластеризация** (пример: сгруппировать отзывы на продукт по тематике, заранее мы не знаем, на какие топики можно поделить отзывы - кластеризация нам в этом поможет)

![](https://habrastorage.org/r/w780/getpro/habr/upload_files/b75/fe6/935/b75fe69350c6210cd5ecf239461c2c53.png)

3. **Обучение с подкреплением:** отдельная большая сложная область машинного обучения, но обычно она выходит за рамки стандартных роадмапов изучения профессии

![](https://habrastorage.org/r/w780/getpro/habr/upload_files/026/eee/814/026eee814d30005197392d62e283475d.png)


## 22. Какие признаки бывают?

- Числовые (возраст, цена)
- Категориальные (цвет, страна)
- Ordinal (Упорядоченные категориальные)
- Булевы (да/нет)
- Временные ряды (температура по дням)
- Текстовые (описание товара)
- Изображения (пиксели)

## 23. Почему переобучение это плохо? Как с ним можно бороться?

**Переобучение** — это ситуация, когда модель слишком хорошо подстраивается под обучающую выборку, включая её шум и выбросы, и теряет способность обобщать на новые, невиданные данные. В итоге, она показывает отличные результаты на тренировке, но проваливается на валидации или в продакшене. Это значит, что модель запомнила данные, а не угадывает закономерность.

![](https://habrastorage.org/r/w780/getpro/habr/upload_files/317/d1c/a72/317d1ca727e47effc2ec1af226f302ab.png)

**Основная цель ML-модели** — хорошо работать на новых данных, а не просто запомнить старые, поэтому с переобучением обязательно нужно бороться и предотвращать его.

**Как бороться с переобучением:**
- **Регуляризация** — добавление штрафа к функции потерь (например, L1 или L2), чтобы ограничить сложность модели.
- **Аугментация данных** — особенно в компьютерном зрении или NLP, помогает расширить датасет и сделать модель устойчивее.
- **Упрощение модели** — уменьшение количества параметров, глубины нейросети / решающего дерева и т.п.
- **Собирание большего количества данных** — лучший способ повысить обобщающую способность, если есть возможность.

## 24. Зачем стандартизировать данные?

Мы приводим признаки к общему масштабу. Это позволяет избежать ситуации, когда один признак с диапазоном [0, 10000] “давит” на другой, у которого разброс от 0 до 1. Не всегда обязательно, но в большинстве случаев — очень желательно. Также такой препроцессинг стабилизирует обучение.

Особенно если ты используешь модели, которые чувствительны к масштабу данных: например, линейную регрессию, логистическую регрессию, k-ближайших соседей, PCA и нейросети. Но стандартизацию делать не всегда обязательно, например, для обучения деревьев не требуется стандартизация.

Пример, когда без нормализации / стандартизации никуда:

Когда обучаем линейную модуль, у нас есть веса при признаках. Если у какого-то признака слишком большой масштаб, то и коэффициент должен быть больше, чтобы скомпенсировать такой масштаб. Таким образом теряется интерпретируемость весов линейной модели, потому что признаки не в равных условиях.

## 25. Что такое гиперпараметр модели? В чем отличие от параметра? Приведи примеры гиперпараметров у пары разных моделей?

**Параметры модели** — это то, что модель *изучает* из данных. Например, веса в линейной регрессии или веса нейронной сети.

**Гиперпараметры** — это параметры, которые задаются до обучения модели и не изменяются во время обучения. Они управляют процессом обучения и архитектурой модели.

Примеры:

Линейная регрессия с L2-регуляризацией (Ridge):
- Параметры: веса модели (коэффициенты при признаках).
- Гиперпараметр: коэффициент регуляризации alpha, который контролирует, насколько сильно мы штрафуем большие веса.

Random Forest:

- Параметры: деревья сами по себе и их сплиты.
- Гиперпараметры: n_estimators (сколько деревьев), max_depth, min_samples_split, и т.п.

## 26. Что такое кросс-валидация?

**Кросс-валидация** — это метод оценки качества модели машинного обучения, при котором данные многократно делятся на обучающую и тестовую выборки, который помогает понять, как она будет работать на новых данных. Идея в том, чтобы не просто один раз разделить данные на train/test, а многократно проверять модель на разных разбиениях данных.

Кросс-валидация помогает получить более хорошую оценку качества модели. Если мы используем стандартный train/test split, то мы сильно зависим от единственного разбиения. Кросс-валидация позволяет получить более устойчивую оценку качества.

![hold-out или обычный трейн/тест сплит](https://habrastorage.org/r/w1560/getpro/habr/upload_files/317/3b2/649/3173b2649178c9d2717f6d9c30cb012c.png)

Допустим, у нас 1000 строк данных.
Мы хотим проверить модель, не тратя целых 30% на тест (дорого!).

**С 5-fold кросс-валидацией:**
- Делим на 5 частей по 200.
- 5 раз обучаем модель на 800 строках и тестируем на 200.
- Считаем среднюю метрику — вот и честная оценка!

Также кросс-валидация очень полезна при подборе гиперпараметров модели, так мы хотим чтобы модель не просто «выучилась» под один тестовый сет, а обобщилась.

![k-fold кросс-валидация](https://habrastorage.org/r/w1560/getpro/habr/upload_files/5ff/96e/012/5ff96e012a4a502a8a4c790c00bb22df.png)

Когда особенно важна кросс-валидация:
- Данных мало.
- Метрика нестабильна.
    * данные неоднородные (например, разная сложность, шум, выбросы),
    * или модель неустойчива и легко переобучается,
    * или выборка маленькая и случай играет большую роль.
- Хочешь точно подобрать гиперпараметры.
- Нужно убедиться, что модель не переобучена.
- Нужно сравнить несколько моделей честно.

## 27. Виды кросс-валидации?

- **k-fold cross-validation** — стандартный вариант.
- **Stratified K-Fold** — если у тебя несбалансированные классы, он сохраняет соотношение классов в каждом фолде.
- **Leave-One-Out (LOO)** — экстремальный случай, где каждый пример по очереди становится валидационным. Тяжёлый, но точный.
- **TimeSeriesSplit** — для временных рядов, где важно сохранять порядок во времени.

Для временных рядов обычный KFold не подойдёт, потому что он ломает хронологию — а во временныхрядах будущее не может «подсматривать» в прошлое. Нужно использовать Time Series Cross‑Validation, или TimeSeriesSplit в sklearn. Суть — мы двигаем «окно» обучения и валидации по временной шкале, сохраняя порядок событий.

![Time series CV](https://habrastorage.org/r/w1560/getpro/habr/upload_files/551/6e6/921/5516e69218ec7c885f06aeab3f56df76.png)

## 28. Что делать, если очень много признаков в датасете? Что такое проклятие размерности?

С одной стороны, если признаков много, это хорошо, потому что больше информации для модели, которую она может извлечь и учитывать в своих предсказаниях.

Но с другой стороны это также может быть вредно для нас:

- долго обучаем модель, долго инферинсим (применяем для тестовых/реальных данных)

- «проклятие размерости» — с увеличением количества признаков нужно экспоненциально больше данных. Плохо работают метрические методы. Много шума в данных, так как не все признаки важны

Если признаков очень много, **особенно если их больше, чем наблюдений** — это уже потенциальная проблема. И называется она красиво — **проклятие размерности**. Суть в том, что по мере роста числа признаков, объёмы пространства растут экспоненциально, и данные становятся всё более разреженными. То есть, условно, в высокоразмерном пространстве даже 10 тысяч точек — это «капля в море». Расстояния между точками теряют смысл, плотности теряют смысл, а модели, особенно те, что зависят от расстояний — например, k-NN, SVM с RBF — начинают вести себя плохо. А ещё — переобучение приходит быстрее.

Есть несколько стратегий для борьбы с проклятием размерности:
- Отбор признаков (Feature selection)
    * Удаление малоинформативных признаков
        + здравым смыслом можем оценить
        + посмотреть на корреляцию с таргетом
        + удалить с большим количеством выбросов
        + удалить признаки с очень низкой дисперсией
    * Удалить мультиколлинеарные признаки (линейно зависимые признаки)
    * Встроенные методы моделей (model-based)
feature_importances_ — встроенный атрибут в RandomForestClassifier, GradientBoostingClassifier и т.д.
    * не забываем про L1 регуляризацию
- Снижение размерности (feature extraction)
    * PCA, t-SNE, UMAP — строят новое пространство меньшей размерности.
- Собрать больше данных
    * Если есть возможность, это всегда помогает компенсировать высокую размерность.

## 29. Какие схемы многоклассовой классификации существуют?

**One-vs-Rest (OvR, или One-vs-All)**

В этой схеме мы обучаем N моделей, где каждая учится отличать один класс против всех остальных.

- Пример: если у тебя 3 класса — A, B, C — ты тренируешь 3 модели:
    * A против (B и C)
    * B против (A и C)
    * C против (A и B)

Инференсим объект по всем моделям и выбираем ту, которая выдала максимальную уверенность. Простая и понятная схема. Часто используется по умолчанию — например, в LogisticRegression(multi_class='ovr') в sklearn.

- используется по умолчанию
- может игнорировать минорные классы

**One-vs-One (OvO)**

Тут всё наоборот: мы обучаем модель для каждой пары классов. То есть, если у тебя N классов, будет N(N-1)/2 моделей.

- Для 3 классов:
    * A vs B
    * A vs C
    * B vs C.
    итого 3 модели

Звучит как очень много моделей, но каждая модель обучается только на части данных так что они маленькие и быстро обучаются. Такая схема хорошо работает с SVM

- используется реже, так как нужно обучать N(N-1)/2 моделей.

**NATIVE**

​​Некоторые модели из коробки поддерживают многоклассовость. Например:

- Деревья, Random Forest, CatBoost — умеют работать с многими классами напрямую.
- Нейросети — просто ставим Softmax на выходе.

## 30. Что такое дисбаланс данных и почему это плохо?

Когда распределение классов в выборке, например, не 50/50, а 90/10.

Модели становится тяжелее предсказывать минорный класс.
Теряется интепретируемость у метрик, например, accuracy.

**Какие методы балансировки датасета бывают?**

**Undersampling**

- Случайное уменьшение выборки мажорного класса

    Просто случайно удаляем часть объектов из «большого» класса. Пример: берём случайные 10% из класса A, чтобы уравнять с B. Быстро, но можно потерять полезную информацию.

- Через кластеризацию

    Обучаем кластеризацию на данных мажорного класса и для каждого кластера из 10ти объектов можем оставить, например, только центр кластера. Дольше, но потенциально теряем меньше полезной информации. Избавляемся от дублей в данных.

**Oversampling**

- Дублируем примеры редкого класса
    * Random Oversampling — просто копируем.

- Генерируем новые
    * SMOTE (Synthetic Minority Oversampling Technique) — генерирует синтетические точки между существующими.
    * ADASYN — как SMOTE, но делает упор на те области, где минорный класс особенно “зажат” мажорным.
    * Можно применять аугментацию данных
        + в компьютерном зрении (CV) — поворачивать изображения и менять у них контрастность, например.
        + в методах работы с текстом (NLP) — случайно вставлять/удалять символы, перефразировать текст или случайные слова заменять синонимами

Конечно, можно и нужно комбинировать.

## 31. Линейные модели

**Что такое линейные модели и как они устроены?**

**Линейные модели** — это класс моделей машинного обучения, в которых предсказание получается как линейная комбинация входных признаков

![Общий вид линейной модели](https://habrastorage.org/r/w1560/getpro/habr/upload_files/2c4/31a/8de/2c431a8de9712d82809985adc2e07818.png)

- x — признаки (входные данные),
- w — веса (коэффициенты модели),
- 𝑏 — свободный член (bias, сдвиг),
- y~ — предсказание модели.

Если представить двумерный случай и задачу классификации.

То есть мы хотим линейно разделить наши классы — тогда веса будут отвечать за угол наклона прямой, а свободный член за ее сдвиг.

![Примеры линейных моделей](https://habrastorage.org/r/w1560/getpro/habr/upload_files/3a5/400/253/3a54002531b98e4ab5a025fc9467328d.png)

Но константу b обычно опускают, потому что для нее используют новый единичный признак.

Основные линейные модели — это линейная регрессия и логистическая регрессия.

**В чем отличие линейной регрессии от логистической регрессии?**

Линейная регрессия:
- Регрессия
- Линейная комбинация признаков
- Лосс — MSE (среднеквадратичная ошибка)

Логистическая регрессия
- Бинарная классификация
- Сигмоида от линейной комбинации признаков, полученное значение интерпретируется как вероятность принадлежности к классу 1
- Логарифмическая функция потерь (log-loss)

**Что такое log-loss, откуда он берется?**

Это функция потерь для бинарной классификации.
Формула выглядит как

![Формула log lossa](https://habrastorage.org/r/w1560/getpro/habr/upload_files/bf2/720/50e/bf272050e07866e541a481846a547199.png)

Чем ближе 𝑝 к истинному классу, тем меньше logloss.

Вывод следующий:
Logloss — это negative log-likelihood
Когда мы обучаем логистическую регрессию, мы по сути максимизируем правдоподобие для распределения Бернулли предсказанных вероятностей на обучающей выборке.

То есть хотим максимизировать величину:

![максимум правдоподобия распределения Бернулли](https://habrastorage.org/r/w1560/getpro/habr/upload_files/003/5b1/70b/0035b170b2bf94683375333ee985d975.png)

Но с произведениями неудобно работать, поэтому прологарифмируем выражение.
А также чтобы решать задачу минимизации, а не максимизации домножим на — 1.
Получаем искомую формулу:

![Снова формула log-loss-а](https://habrastorage.org/r/w1560/getpro/habr/upload_files/229/7e0/a83/2297e0a83609b111dc8683a1dd7e48a0.png)

**Какие есть плюсы и минусы у линейных моделей?**
Плюсы:
- Простота
- Быстрое обучение
- Интерпретируемость
- Не требуют большого кол-ва данных
- Хорошо работают с трендами

Минусы:
- Плохо работают с нелинейными зависимостями
- Чувствительны к выбросам
- Требуют нормализации признаков

**Как можно интерпретировать линейные модели?**

Через знак веса:
- 𝑤>0: признак положительно влияет на целевую переменную.
- 𝑤<0: признак отрицательно влияет.
- 𝑤=0: признак не влияет (или модель считает его бесполезным).

Модуль веса:
- Чем больше абсолютное значение, тем более важен этот признак для модели.

Важно:
- Но сравнивать можно только после нормализации признаков, иначе масштабы «врут».
- Больше верим коэффициенту при использовании регуляризации и / или отсутствии мультиколлинеарности.

## 32. Что такое мультиколлинеарность? Как ее победить?

**Мультиколлинеарность** — это ситуация, когда некоторые признаки сильно коррелируют друг с другом.

Почему это плохо:
- Веса могут по модулю сильно увеличиваться да и вообще становятся нестабильными.
- Плохая интерпретируемость.

Что можно сделать:
- Удаление коррелированных признаков
- Регуляризация

## 33. Как заподозрить переобучение у линейной модели?

Кроме того, чтобы считать метрики качества на отложенной выборке, можно посмотреть на коэффициенты перед признаки у обученной модели.

Если они очень большие, выглядят неадекватно и потеряли интерпретируемость, то, скорее всего, модель переобучилась.

## 34. Что такое регуляризация в линейных моделях? Какие бывают и в чем их особенности?

**Регуляризация** — это способ борьбы с переобучением, когда мы накладываем на модель дополнительные ограничения, чтобы сделать ее проще, устойчивее и с лучшей обобщающей способностью.

**Регуляризация в линейных моделях** — это добавка к функции потерь, которая штрафует модель за слишком сложные решения — обычно за большие веса.

![вид функционала качество (лосс функции) с членом регуляризации](https://habrastorage.org/r/w1560/getpro/habr/upload_files/d1e/a39/f25/d1ea39f2553e7214eba980b9b96772a1.png)

λ – это очередной гиперпараметр
А штраф за большие веса может быть в виде L1 — нормы коэффициентов или L2.

**L1 (Lasso)**

![L1 регуляризация (L1/Манхэттанская норма)](https://habrastorage.org/r/w1560/getpro/habr/upload_files/4a4/7ea/a92/4a47eaa92c1f21ff1e1b5e83bdbd3c1e.png)

**L2 (Ridge)**

![L2 регуляризация (L2/Евклидова норма)](https://habrastorage.org/r/w1560/getpro/habr/upload_files/7d0/14b/9ba/7d014b9bafb78ae72c5c2de2ef2a9768.png)

**ElasticNet**

Комбинация L1 и L2.
Кроме того, что L1 и L2 уменьшают нормы весов, L1 еще и зануляет коэффициенты при неважных признаках из-за природы своей геометрической интерпретации.

**Какая геометрическая интепретация L1 и L2 регуляризаций?**

![Смотрим на пересечение линий уровня лоссов и регуляризаций](https://habrastorage.org/r/w1560/getpro/habr/upload_files/222/2a2/479/2222a2479e088b74e33d5a889cba9963.png)

**Линии уровня L1** — N‑мерные октаэдры, поэтому пересечение с линиями уровня основной лосс функции будет, скорее всего, на осях, где один из признаков обнуляется.

**Как обучаются линейные модели (2 способа)?**

*Способ 1: Аналитическое решение*

Решаем уравнение напрямую через линейную алгебру

![Аналитическое решение](https://habrastorage.org/r/w1560/getpro/habr/upload_files/a2a/9a5/aeb/a2a9a5aeb7deaa966b0982f2ca65ae51.png)

Не используется в больших задачах, т.к. требует обращать матрицу - а это дорого и может быть вырожденной (при мультиколлинеарности).

*Способ 2: Градиентный спуск*

![Градиентный способ](https://habrastorage.org/r/w1560/getpro/habr/upload_files/b0f/efa/33e/b0fefa33e5ee7d66f2205271f51f06f4.png)

Так как у нас есть функция потерь, она дифференциремая, то есть если посчитать градиент этой функции, то антиградиент покажет, куда нужно смещаться для наискорейшего убывания.
Смещаться будем итеративно со скоростью обучения, которую часто называют learning rate.
Также для ускорения оптимизации можно считать градиент не по всем объектам выборки, а по батчам.

![Отличия SGD от GD](https://habrastorage.org/r/w1560/getpro/habr/upload_files/ec4/406/4cf/ec44064cf2fee6392f5b1058f6b3644a.png)

## 35. Метрики классификации и регрессии

**Метрики регрессии**
**МАЕ** — значение ошибки по модулю.

$$ \sum_{i=1}^{D}|x_i-y_i| $$

**MSE** — Квадрат ошибки. Очень чувствителен к выбросам. Если хотим показывать в out of distribution (выбросы). 

$$ \sum_{i=1}^{D}(x_i-y_i)^2 $$

Если хотим уделить внимание выбросам и их учитывать в обучении, то используем MSE.  Если оне не важны, то лучше использовать МАЕ.

**RMSE** — косметическая надстройка над MSE, просто берем корень из MSE, чтобы посмотреть на ошибку в нормальных значениях, так как из квадрата не сразу понятно, например, квадратные рубли.

![Разница MSE и MAE](https://habrastorage.org/r/w1560/getpro/habr/upload_files/9d1/d1d/cae/9d1d1dcaec7b6137822974cadea5b1b8.png)

**R2** — показывает, какая доля дисперсии объяснима моделью. Используется, когда нужно понять на сколько плохая или хорошая модель.

![Формула R^2](https://habrastorage.org/r/w1560/getpro/habr/upload_files/ae1/175/13f/ae117513ff8152615f6b1bf2d44b84e1.png)

Если ошибка маленькая, то в числителе будет маленькое значение и **R2** большое, например, 0,8, то модель объясняет 80% всех данных. Интуитивно: лучше ли модель чем просто усреднение таргета

**RMSLE, MAPE, WAPE** — для подсчета относительных ошибок, когда нам не так важна абсолютная ошибка, а именно относительная

- пример: ошибка в стоимости автомобилей

## 36. Метрики классификации

**Accuracy** — доля правильных ответов относительно всех объектов. Берет только правильные ответы на всех классах. У нее проблемы:
- дисбаланс классов — если объектов 1 класса сильно больше чем другого, то метрика не инфомративна
- разная цена ошибок — если в задаче классификации одна ошибка стоит больше чем другая, то эту метрику применять не стоит. Пример: выдача кредита или обнаружение заболевания 

![Accuracy](https://habrastorage.org/r/w1560/getpro/habr/upload_files/7c3/83c/788/7c383c7881c6ddda339377011a530952.png)

**Precision (Точность)** — Доля релевантных среди найденных.
Пример: Классификация хороший ли день для запуска спутника по погоде. Мы можем пропустит хороший день, но нам нельзя лететь в плохую погоду точно.

![Формула precision](https://habrastorage.org/r/w1560/getpro/habr/upload_files/8df/4cb/3d9/8df4cb3d9bba2a9b33dbf3ff73fa5203.png)

**Recall (Полнота)** — Покрытие целевого класса (класса 1). Долю найденных из всех релевантных.
Пример: модель которая выбирает больных из здоровых, пусть лучше выбирает всех, чем кого-то пропустит.

![Формула recall](https://habrastorage.org/r/w1560/getpro/habr/upload_files/b6f/17c/8e1/b6f17c8e12a28678c337fd7ca9f525ab.png)

![Сравнение точности и полноты](https://habrastorage.org/r/w1560/getpro/habr/upload_files/c72/dcc/d89/c72dccd896588f1df57f1ad11b073fb5.png)

**F1 мера**, это среднее гармоническое между точностью и полнотой. Если хотя бы один из аргументов стремится к нулю, то и вся модель стремится к нулю (в отличие от среднего арифмитического). Когда хотим найти оптимизировать и precision, и recall.

![F1-score](https://habrastorage.org/r/w1560/getpro/habr/upload_files/f57/bdc/8d3/f57bdc8d3b76aa27990c53cd915f7d51.png)

F1-мера помогает бороться с дисбалансом классов, потому что она учитывает и **Precision (точность)**, и **Recall (полноту)**, а не просто количество правильно предсказанных примеров, как Accuracy.
**Fb score** — та же метрика, но используется, если требуется отдать предпочтение одной из метрик: точности или полноте.
**Roc-Auc-score** площадь под ROC кривой в осях TPR и FPR. Дает интегральную оценку модели при любых порогах. А также показывает долю верно упорядоченных пар объектов с разных классов.

![Roc-Auc-score](https://habrastorage.org/r/w1560/getpro/habr/upload_files/b2d/6d9/418/b2d6d94184d70554fa0205953b1a02f9.png)

Пример:
Отток клиентов, нужно не просто классифицировать клиентов, а еще и понять на сколько классификатор уверен. Если человек с малой вероятностью оттечет, то ему дать купон. Если с большой, то предложить классный тариф.

**Precision-Recall AUC (PR AUC)**

Строит кривую в осях Precision Recall и вычисляет площадь под ней.
Лучше подходит для сильно несбалансированных данных, чем обычный ROC AUC.

**Метрики для многоклассовой классификации**
Микроусреднение — усредняем элементы матрицы ошибок (TP, FP, TN, FN) между бинарными классификаторами и потом по усредненной матрице неточностей считаем precision и recall может плохо отражать качество при дисбалансе

**Макроусреднение** — сначала по классам считаем precision и recall, а затем усредняем все значения в финальные метрики precision и recall. Лучше отражает плохие значения при дисбалансе.

**Ассиметричные метрики**
Асимметричные метрики — это метрики, которые по-разному оценивают ошибку в зависимости от направления отклонения предсказания от истинного значения. То есть, ошибка в одну сторону (переоценка или недооценка) "наказывается" сильнее, чем в другую.
- В кредитном скоринге: лучше недооценить платёжеспособность клиента, чем переоценить.
- В прогнозировании спроса: недооценка спроса приводит к дефициту товара, а переоценка — к избыточным запасам. Иногда первое хуже второго, иногда наоборот.
